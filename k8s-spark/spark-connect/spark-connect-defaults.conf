spark.master                              k8s://https://kubernetes.default.svc  # tell Spark which cluster manager to talk to. In this case, the K8S API server
spark.kubernetes.namespace                spark-operator
spark.kubernetes.authenticate.driver.serviceAccountName  spark-all-purpose-driver1
spark.kubernetes.container.image          docker.io/library/spark:4.0.0
spark.kubernetes.executor.deleteOnTermination: "false"

# To support Spark History Server
spark.eventLog.enabled: "true"
spark.eventLog.dir: "file:///tmp/spark-events"

# Executor sizing (base/default)
spark.executor.cores                      2
spark.executor.memory                     4g

# Dynamic Allocation (Databricks-like behavior)
spark.dynamicAllocation.enabled           true
spark.dynamicAllocation.shuffleTracking.enabled true    # K8S: no external shuffle svc
spark.shuffle.service.enabled             false         # K8S: keep this false
spark.dynamicAllocation.initialExecutors  2
spark.dynamicAllocation.minExecutors      2
spark.dynamicAllocation.maxExecutors      50
spark.dynamicAllocation.executorIdleTimeout           900s    # Keep executors warm longer
spark.dynamicAllocation.cachedExecutorIdleTimeout     86400s  # Set to "infinity" to never remove executors with cached data

# Tame pod churn on K8S
spark.kubernetes.allocation.batch.size         5
spark.kubernetes.allocation.executor.timeout   120s

# Make Spark Connect the front door
spark.connect.grpc.binding.port                15002

# Configs for multiple users to share this driver
spark.scheduler.mode                           FAIR
spark.sql.adaptive.enabled                     true
spark.sql.adaptive.coalescePartitions.enabled  true