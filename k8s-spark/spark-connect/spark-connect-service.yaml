apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-connect1  # Spark Connect server is the long-running driver Deployment
                       # Spark Connect client lives in notebook, IDE, or PySpark script; it translates user code into
                       # a serialized logical plan and sends it over gRPC
  namespace: spark-operator
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-connect1
  template:
    metadata:
      labels:
        app: spark-connect1
    spec:
      serviceAccountName: spark-all-purpose-driver1
      initContainers:
        - name: create-event-log-dir
          image: busybox:1.36
          command: [ 'sh', '-c', 'mkdir -p /tmp/spark-events && chown -R 185:185 /tmp/spark-events && chmod 755 /tmp/spark-events' ]
          volumeMounts:
            - name: spark-events
              mountPath: /tmp/spark-events
      containers:
        - name: driver
          image: docker.io/library/spark:4.0.0
          # Spark Connect server binary reads spark-defaults.conf we mount
          # This creates a JVM driver process using `org.apache.spark.sql.connect.service.SparkConnectServer` and
          # initializes a SparkSession, registers with the cluster manager.
          command: ["/opt/spark/sbin/start-connect-server.sh"]
          resources: # The node resources can be found through `kubectl describe node prod-test-worker`
            requests:
              memory: "1500Mi" # or 2Gi
              cpu: "2000m"
            limits:
              memory: "1500Mi"
          ports:
            - containerPort: 15002  # optional section because it's the default port for Spark Connect gRPC
              name: connect
            - containerPort: 4040   # optional section because it's the default port for Spark UI
              name: spark-ui
          readinessProbe:
            tcpSocket:
              port: 15002
            initialDelaySeconds: 10
            periodSeconds: 5
          livenessProbe:
            tcpSocket:
              port: 15002
            initialDelaySeconds: 10
            periodSeconds: 10
          env:
            - name: SPARK_NO_DAEMONIZE # Tells Spark startup scripts (like start-connect-server.sh, start-thriftserver.sh, etc.)
                                       # to run in the foreground instead of daemonizing.
                                       # Kubernetes expects the main container process (PID 1) to stay in the foreground.
                                       # If the script daemonizes, the pod will exit immediately after startup.
              value: "true"
            - name: SPARK_DRIVER_EXTRA_CLASSPATH
              value: ""                # To add custom jars that arenâ€™t in `/opt/spark/jars`
            - name: SPARK_CONF_DIR
              value: /opt/spark/conf
            - name: SPARK_APP_NAME  # spark.app.name is customizable, but application id isn't
                                    # application id will be generated when the Spark Connect driver starts. It can be read as below
                                    # kubectl logs spark-connect-b4f58bdd4-r2pg9 -n spark-operator | grep -i "application\|appid"
              value: all-purpose1
          volumeMounts:
            - name: spark-events
              mountPath: /tmp/spark-events
            - name: spark-default-conf
              mountPath: /opt/spark/conf
      volumes:
        - name: spark-events
          persistentVolumeClaim:
            claimName: spark-events-pvc
        - name: spark-default-conf
          configMap:
            name: spark-connect-default-conf
---
apiVersion: v1
kind: Service
metadata:
  name: spark-connect1-svc
  namespace: spark-operator
spec:
  type: ClusterIP
  selector:
    app: spark-connect1
  ports:
    - port: 15002
      targetPort: 15002
      protocol: TCP
      name: connect
    - port: 4040  # This section is optional because users can access WebUI through the driver's port
      targetPort: 4040
      protocol: TCP
      name: spark-ui