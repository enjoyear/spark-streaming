## tell Spark which cluster manager to talk to. In this case, the K8S API server
spark.master                              k8s://https://kubernetes.default.svc
spark.kubernetes.namespace                spark-operator
spark.kubernetes.authenticate.driver.serviceAccountName  spark-all-purpose-driver1
spark.kubernetes.container.image          docker.io/library/spark:4.0.0
spark.kubernetes.executor.deleteOnTermination: false

# To support Spark History Server
spark.eventLog.enabled:         true
spark.eventLog.dir:             "file:///tmp/spark-events"

# Executor sizing (base/default)
spark.executor.cores                      2
spark.executor.memory                     4g

# Dynamic Allocation (Databricks-like behavior)
spark.dynamicAllocation.enabled           true
## In K8S setup, there is no external shuffle svc
spark.dynamicAllocation.shuffleTracking.enabled true
## In K8S setup: keep this false
spark.shuffle.service.enabled             false
spark.dynamicAllocation.initialExecutors  2
spark.dynamicAllocation.minExecutors      2
spark.dynamicAllocation.maxExecutors      50
## Keep executors warm longer
spark.dynamicAllocation.executorIdleTimeout           900s
## Set to "infinity" to never remove executors with cached data
spark.dynamicAllocation.cachedExecutorIdleTimeout     86400s

# Tame pod churn on K8S
spark.kubernetes.allocation.batch.size         5
spark.kubernetes.allocation.executor.timeout   120s

# Make Spark Connect the front door
spark.connect.grpc.binding.port                15002

# Configs for multiple users to share this driver
spark.scheduler.mode                           FAIR
spark.sql.adaptive.enabled                     true
spark.sql.adaptive.coalescePartitions.enabled  true